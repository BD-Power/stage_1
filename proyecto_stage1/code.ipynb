{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "CTRL = Path(\"control\")\n",
    "CTRL.mkdir(exist_ok=True)\n",
    "\n",
    "LOG_CSV   = CTRL / \"control_log.csv\"\n",
    "DOWN_TXT  = CTRL / \"downloaded_books.txt\"\n",
    "\n",
    "START_MARKER = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "END_MARKER   = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "def already_downloaded(book_id: int) -> bool:\n",
    "    # Verifica si el libro ya está registrado como descargado\n",
    "    return DOWN_TXT.exists() and str(book_id) in DOWN_TXT.read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "def download_book(book_id: int, base: str = \"datalake\") -> tuple[Path, Path] | None:\n",
    "    if already_downloaded(book_id):\n",
    "        print(f\"[SKIP] {book_id} was already downloaded\")\n",
    "        return None\n",
    "    \n",
    "    # Particionado por fecha y hora de INGESTIÓN\n",
    "    now = datetime.now()\n",
    "    base_dir = Path(base) / now.strftime(\"%Y%m%d\") / now.strftime(\"%H\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt\"\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    text = resp.text\n",
    "\n",
    "    if START_MARKER not in text or END_MARKER not in text:\n",
    "        print(f\"[ERROR] Marcadores no encontrados en el libro {book_id}\")\n",
    "        return None\n",
    "\n",
    "    header, body_and_footer = text.split(START_MARKER, 1)\n",
    "    body, _footer = body_and_footer.split(END_MARKER, 1)\n",
    "\n",
    "    header_path = base_dir / f\"{book_id}.header.txt\"\n",
    "    body_path   = base_dir / f\"{book_id}.body.txt\"\n",
    "\n",
    "    header_path.write_text(header.strip(), encoding=\"utf-8\")\n",
    "    body_path.write_text(body.strip(), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[OK] {book_id} -> {header_path} / {body_path}\")\n",
    "    return header_path, body_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for the Control Log\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def register_in_control(book_id: int, header_path: Path, body_path: Path, state=\"OK\"):\n",
    "    if not LOG_CSV.exists():\n",
    "        with open(LOG_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow([\"book_id\", \"date\", \"header_file\", \"body_file\", \"state\"])\n",
    "    with open(LOG_CSV, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow([\n",
    "            book_id,\n",
    "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            str(header_path),\n",
    "            str(body_path),\n",
    "            state\n",
    "        ])\n",
    "\n",
    "    with open(DOWN_TXT, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{book_id}\\n\")\n",
    "\n",
    "    print(f\"[CONTROL] Registrado {book_id} en control_log.csv y downloaded_books.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] 1342 was already downloaded\n",
      "[SKIP] 11 was already downloaded\n",
      "[SKIP] 84 was already downloaded\n"
     ]
    }
   ],
   "source": [
    "def download_multiple(ids: list[int]):\n",
    "    # Recorre la lista de IDs para descargar cada libro\n",
    "    for bid in ids:\n",
    "        if already_downloaded(bid):\n",
    "            # Si ya estaba descargado, se omite\n",
    "            print(f\"[SKIP] {bid} was already downloaded\")\n",
    "            continue\n",
    "        res = download_book(bid)   # Usa tu función existente para descargar\n",
    "        if res:\n",
    "            header_path, body_path = res\n",
    "            register_in_control(bid, header_path, body_path)  # Registra en el control\n",
    "\n",
    "\n",
    "download_multiple([1342, 11, 84])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from collections import defaultdict\n",
    "\n",
    "DATALAKE_PATH = Path(\"datalake\")\n",
    "DATAMARTS_PATH = Path(\"datamarts\"); DATAMARTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Convierte el texto en una lista de palabras en minúsculas,\n",
    "    eliminando cualquier carácter que no sea alfanumérico.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return words\n",
    "\n",
    "def build_inverted_index() -> dict[str, set[int]]:\n",
    "    inverted_index = defaultdict(set)\n",
    "    for body_file in DATALAKE_PATH.rglob(\"*.body.txt\"):\n",
    "        book_id = int(body_file.stem.split(\".\")[0])   \n",
    "        text = body_file.read_text(encoding=\"utf-8\")\n",
    "        words = tokenize(text)\n",
    "        for word in words:\n",
    "            inverted_index[word].add(book_id)\n",
    "    return inverted_index\n",
    "\n",
    "\n",
    "def save_inverted_index(index: dict[str, set[int]]):\n",
    "    \"\"\"\n",
    "    Guarda el índice invertido en formato JSON dentro de datamarts/\n",
    "    \"\"\"\n",
    "    json_path = DATAMARTS_PATH / \"inverted_index.json\"\n",
    "    # Convertimos los sets a listas para que sean serializables en JSON\n",
    "    serializable_index = {word: list(ids) for word, ids in index.items()}\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(serializable_index, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[OK] Inverted index saved at {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 43 -> datalake\\20251002\\16\\43.header.txt / datalake\\20251002\\16\\43.body.txt\n",
      "[CONTROL] Registrado 43 en control_log.csv y downloaded_books.txt\n",
      "[OK] 56 -> datalake\\20251002\\16\\56.header.txt / datalake\\20251002\\16\\56.body.txt\n",
      "[CONTROL] Registrado 56 en control_log.csv y downloaded_books.txt\n",
      "[OK] Inverted index built\n",
      "[OK] Inverted index saved at datamarts\\inverted_index.json\n",
      "Results for 'love': {11, 43, 15, 84, 1342}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    book_ids = [43, 56]\n",
    "\n",
    "    for book_id in book_ids:\n",
    "        if already_downloaded(book_id):   \n",
    "            print(f\"[SKIP] {book_id} was already downloaded\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            res = download_book(book_id)\n",
    "            if res:\n",
    "                header_file, body_file = res\n",
    "                register_in_control(book_id, header_file, body_file)\n",
    "            else:\n",
    "                register_in_control(book_id, \"-\", \"-\", state=\"FAILED\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed downloading {book_id}: {e}\")\n",
    "            register_in_control(book_id, \"-\", \"-\", state=\"FAILED\")\n",
    "\n",
    "    inverted_index = build_inverted_index()\n",
    "    print(\"[OK] Inverted index built\")\n",
    "\n",
    "    save_inverted_index(inverted_index)\n",
    "\n",
    "    word = \"love\"\n",
    "    results = inverted_index.get(word.lower(), set())\n",
    "    print(f\"Results for '{word}': {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gabriel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
